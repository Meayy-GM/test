import streamlit as st
import pandas as pd
from gingerit.gingerit import GingerIt
import re

st.set_page_config(page_title="Grammar Checker", layout="wide")
st.title("ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è‹±æ–‡æ³•ãƒã‚§ãƒƒã‚«ãƒ¼")

st.markdown("""
è‹±èªã®æ–‡ç« ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡æ³•ãƒ»ã‚¹ãƒšãƒ«ãƒŸã‚¹ã‚’æ¤œå‡ºã—ã¦ä¸€è¦§è¡¨ç¤ºã—ã¾ã™ã€‚  
Gingerit ã‚’ä½¿ç”¨ã—ã¦åˆ†æã—ã¦ã„ã¾ã™ã€‚
""")

user_text = st.text_area(
    "è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", 
    height=200, 
    placeholder="ã“ã“ã«è‹±æ–‡ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ã™ãã«ãƒã‚§ãƒƒã‚¯çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
)

# Gingeritã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä¸€åº¦ã ã‘ä½œæˆ
@st.cache_resource
def get_parser():
    return GingerIt()

parser = get_parser()

def split_long_text(text, max_length=600):
    """é•·ã„æ–‡ç« ã‚’çŸ­ã„ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
    if len(text) <= max_length:
        return [text]
    
    # æ–‡ã§åˆ†å‰²ã‚’è©¦ã¿ã‚‹
    sentences = re.split(r'[.!?]+\s+', text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk + sentence) <= max_length:
            current_chunk += sentence + ". "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def find_differences(original, corrected):
    """åŸæ–‡ã¨ä¿®æ­£æ–‡ã®é•ã„ã‚’æ¤œå‡º"""
    if original.strip() == corrected.strip():
        return []
    
    # ç°¡å˜ãªå˜èªãƒ¬ãƒ™ãƒ«ã®å·®åˆ†æ¤œå‡º
    original_words = original.split()
    corrected_words = corrected.split()
    
    differences = []
    
    # é•·ã•ãŒç•°ãªã‚‹å ´åˆã‚„å¤§ããå¤‰ã‚ã£ãŸå ´åˆ
    if len(original_words) != len(corrected_words) or original != corrected:
        differences.append({
            "ã‚¨ãƒ©ãƒ¼ç®‡æ‰€": "æ–‡ç« å…¨ä½“",
            "ç†ç”±": "æ–‡æ³•ãƒ»èªæ³•ãƒ»ã‚¹ãƒšãƒ«ã®ä¿®æ­£",
            "ææ¡ˆ": "ä¿®æ­£å¾Œã®æ–‡ç« ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
        })
    
    return differences

if user_text.strip():
    try:
        with st.spinner("æ–‡æ³•ãƒã‚§ãƒƒã‚¯ä¸­..."):
            # é•·æ–‡ã®å ´åˆã¯åˆ†å‰²ã—ã¦å‡¦ç†
            chunks = split_long_text(user_text)
            all_issues = []
            corrected_chunks = []
            
            for chunk in chunks:
                # Gingeritã§è§£æ
                result = parser.parse(chunk)
                corrected_chunk = result.get('result', chunk)
                corrected_chunks.append(corrected_chunk)
                
                # å…ƒã®Gingeritã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚’ç¢ºèª
                st.write("Debug - Gingerit response:", result)  # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼ˆæœ¬ç•ªã§ã¯å‰Šé™¤ï¼‰
                
                # ä¿®æ­£ãŒã‚ã£ãŸå ´åˆã®å·®åˆ†ã‚’æ¤œå‡º
                if chunk != corrected_chunk:
                    differences = find_differences(chunk, corrected_chunk)
                    all_issues.extend(differences)
            
            corrected_text = ' '.join(corrected_chunks)
            
            # çµæœè¡¨ç¤º
            if not all_issues:
                if user_text.strip() != corrected_text.strip():
                    st.warning("ğŸš¨ æ–‡ç« ãŒä¿®æ­£ã•ã‚Œã¾ã—ãŸã€‚")
                    all_issues = [{
                        "ã‚¨ãƒ©ãƒ¼ç®‡æ‰€": "æ–‡ç« ",
                        "ç†ç”±": "æ–‡æ³•ãƒ»ã‚¹ãƒšãƒ«ãŒæ”¹å–„ã•ã‚Œã¾ã—ãŸ",
                        "ææ¡ˆ": "ä¿®æ­£å¾Œã®æ–‡ç« ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                    }]
                else:
                    st.success("âœ… æ–‡æ³•ãƒŸã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.warning(f"ğŸš¨ ä¿®æ­£ãŒé©ç”¨ã•ã‚Œã¾ã—ãŸã€‚")
            
            if all_issues:
                df = pd.DataFrame(all_issues)
                st.dataframe(df, use_container_width=True)
            
            # ä¿®æ­£æ¸ˆã¿æ–‡ç« ã‚’è¡¨ç¤º
            with st.expander("âœï¸ ä¿®æ­£å¾Œã®æ–‡ç« ã‚’è¡¨ç¤º"):
                st.text_area("ä¿®æ­£å¾Œ:", value=corrected_text, height=150)
                
                # å…ƒã®æ–‡ç« ã‚‚æ¯”è¼ƒã®ãŸã‚ã«è¡¨ç¤º
                st.text_area("å…ƒã®æ–‡ç« :", value=user_text, height=150)

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        st.info("1. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒæ­£å¸¸ã‹")
        st.info("2. å…¥åŠ›æ–‡ç« ã®é•·ã•ï¼ˆé•·ã™ãã‚‹å ´åˆã¯åˆ†å‰²ã—ã¦å…¥åŠ›ï¼‰")
        st.info("3. ç‰¹æ®Šæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹")

else:
    st.info("â¬… ä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«è‹±èªã®æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
with st.expander("ğŸ“– ä½¿ç”¨æ–¹æ³•"):
    st.markdown("""
    **ä½¿ã„æ–¹:**
    1. ä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«è‹±èªã®æ–‡ç« ã‚’å…¥åŠ›
    2. è‡ªå‹•çš„ã«æ–‡æ³•ãƒ»ã‚¹ãƒšãƒ«ãƒã‚§ãƒƒã‚¯ãŒå®Ÿè¡Œã•ã‚Œã¾ã™
    3. ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ä¸€è¦§è¡¨ç¤ºã•ã‚Œã¾ã™
    4. ä¿®æ­£å¾Œã®æ–‡ç« ã¯æŠ˜ã‚ŠãŸãŸã¿ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã§ç¢ºèªã§ãã¾ã™
    
    **æ³¨æ„:**
    - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™
    - é•·ã„æ–‡ç« ã¯è‡ªå‹•çš„ã«åˆ†å‰²ã—ã¦å‡¦ç†ã•ã‚Œã¾ã™
    - å‡¦ç†ã«æ•°ç§’ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™
    """)